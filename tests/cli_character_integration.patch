--- regender_book_cli.py.orig	2024-01-01 00:00:00.000000000 +0000
+++ regender_book_cli.py	2024-01-01 00:00:00.000000000 +0000
@@ -160,7 +160,8 @@
 def transform_single_book(input_file: str, output_file: Optional[str] = None, 
                          text_output: Optional[str] = None, transform_type: str = "comprehensive",
-                         model: str = "gpt-4o-mini", provider: Optional[str] = None, quiet: bool = False):
+                         model: str = "gpt-4o-mini", provider: Optional[str] = None, 
+                         character_file: Optional[str] = None, quiet: bool = False):
     """Transform a single JSON book."""
     if not quiet:
         print(f"\n{CYAN}ðŸ“– Processing: {input_file}{RESET}")
@@ -193,6 +194,9 @@
         else:
             print(f"ðŸ¤– Model: {model}")
     
+    if character_file and not quiet:
+        print(f"ðŸ“‹ Characters: {character_file}")
+    
     # Transform the book
     try:
         # Use actual model name from provider if available
@@ -206,11 +210,20 @@
                 pass
         
         start_time = time.time()
-        transformed_data = transform_book(
-            book_data,
-            transform_type=transform_type,
-            model=actual_model,
-            provider=provider,
-            verbose=not quiet
-        )
+        
+        if character_file:
+            # Use character-based transformation
+            from book_transform.utils import transform_with_characters
+            transformed_data = transform_with_characters(
+                book_data,
+                character_file=character_file,
+                transform_type=transform_type,
+                model=actual_model,
+                provider=provider,
+                verbose=not quiet
+            )
+        else:
+            # Standard transformation
+            transformed_data = transform_book(
+                book_data,
+                transform_type=transform_type,
+                model=actual_model,
+                provider=provider,
+                verbose=not quiet
+            )
+        
         elapsed = time.time() - start_time
         
@@ -238,6 +250,30 @@
         sys.exit(1)
 
 
+def analyze_characters_command(input_file: str, output_file: str, 
+                              model: str = "gpt-4o-mini", provider: Optional[str] = None):
+    """Analyze and save character data from a book."""
+    print(f"\n{CYAN}ðŸ“– Analyzing characters in: {input_file}{RESET}")
+    
+    # Load book
+    book_data = load_json_book(input_file)
+    
+    # Analyze characters
+    from book_transform.character_analyzer import analyze_book_characters
+    characters, context = analyze_book_characters(
+        book_data,
+        model=model,
+        provider=provider,
+        verbose=True
+    )
+    
+    # Save character data
+    save_book_json({'characters': characters, 'context': context}, output_file)
+    
+    print(f"\n{GREEN}âœ“ Saved {len(characters)} characters to: {output_file}{RESET}")
+    return characters
+
+
 def batch_transform(input_dir: str = "books/json", output_dir: str = "books/output",
                    transform_type: str = "comprehensive", model: str = "gpt-4o-mini",
@@ -379,6 +415,7 @@
     transform_parser.add_argument('--model', default='gpt-4o-mini', help='Model to use')
     transform_parser.add_argument('--provider', choices=['openai', 'grok', 'mlx'], help='LLM provider to use')
+    transform_parser.add_argument('--characters', help='Pre-analyzed character file to use')
     transform_parser.add_argument('--batch', action='store_true', help='Process directory of files')
     transform_parser.add_argument('--limit', type=int, help='Limit number of files in batch mode')
     
+    # Analyze characters command
+    analyze_parser = subparsers.add_parser('analyze-characters', help='Analyze and save character data')
+    analyze_parser.add_argument('input', help='Input JSON book file')
+    analyze_parser.add_argument('-o', '--output', required=True, help='Output character file')
+    analyze_parser.add_argument('--model', default='gpt-4o-mini', help='Model to use')
+    analyze_parser.add_argument('--provider', choices=['openai', 'grok', 'mlx'], help='LLM provider')
+    
     # Pipeline command
@@ -421,7 +463,11 @@
                 output_file = str(input_path.parent / f"{input_path.stem}_transformed.json")
             
-            transform_single_book(args.input, output_file, args.text, args.type, args.model, args.provider)
+            transform_single_book(args.input, output_file, args.text, args.type, 
+                                args.model, args.provider, args.characters)
+    
+    elif args.command == 'analyze-characters':
+        analyze_characters_command(args.input, args.output, args.model, args.provider)
     
     elif args.command == 'pipeline':