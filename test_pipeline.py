#!/usr/bin/env python3
"""
CONSOLIDATED PIPELINE TESTING
Single script to test the complete AI chunking + gender transformation pipeline.
"""

import sys
import time
import argparse
from pathlib import Path
from ai_chunking import chunk_text_ai
from gender_transform import transform_gender_with_context
from analyze_characters import analyze_characters

def test_pipeline(book_path: str, book_name: str, transform_type: str = "neutral", save_output: bool = False):
    """Test the complete pipeline: AI chunking + character analysis + transformation.
    
    Args:
        book_path: Path to the book file
        book_name: Name of the book for display
        transform_type: Type of transformation (neutral, feminine, masculine)
        save_output: Whether to save the transformed output to file
        
    Returns:
        bool: Success status
    """
    print(f"ğŸš€ TESTING AI PIPELINE: {book_name.upper()}")
    print(f"ğŸ“– Transform type: {transform_type}")
    print(f"ğŸ’¾ Save output: {'Yes' if save_output else 'No'}")
    print("=" * 80)
    
    # Step 1: Load the book
    try:
        with open(book_path, 'r') as f:
            full_text = f.read()
    except FileNotFoundError:
        print(f"âŒ {book_name} not found at {book_path}!")
        return False
    
    print(f"ğŸ“š Loaded {book_name}: {len(full_text):,} characters")
    
    # Step 2: AI chunking
    print(f"\nğŸ”§ AI CHUNKING...")
    chunks = chunk_text_ai(full_text, prefer_ai=False)  # Use Python fallback for speed
    
    if not chunks:
        print(f"âŒ AI chunking failed for {book_name}")
        return False
    
    print(f"âœ… Created {len(chunks)} chunks with 100% coverage")
    
    # Step 3: Character analysis
    print(f"\nğŸ‘¥ CHARACTER ANALYSIS...")
    start_time = time.time()
    
    try:
        # Analyze characters on a sample (first few chunks) to save time/quota
        sample_text = chunks[0]['text'] + (chunks[1]['text'] if len(chunks) > 1 else '')
        character_analysis = analyze_characters(sample_text[:50000])  # First 50k chars
        
        characters_dict = character_analysis.get('characters', {})
        character_list = []
        for name, char_info in characters_dict.items():
            character_list.append({
                'name': name,
                'gender': char_info.get('gender', 'unknown'),
                'role': char_info.get('role', 'Unknown role')
            })
        
        analysis_time = time.time() - start_time
        print(f"âœ… Identified {len(character_list)} characters in {analysis_time:.1f}s")
        
        # Show key characters
        for char in character_list[:3]:
            print(f"   - {char['name']}: {char['gender']}, {char['role']}")
            
    except Exception as e:
        print(f"âŒ Character analysis failed: {e}")
        # Fallback: use simple character context
        character_list = [{"name": "Main Character", "gender": "unknown", "role": "protagonist"}]
    
    # Step 4: Test transformation on first chunk
    print(f"\nğŸ”„ TESTING TRANSFORMATION ON FIRST CHUNK...")
    first_chunk = chunks[0]
    chunk_size = first_chunk['size']
    estimated_tokens = chunk_size // 4
    
    print(f"ğŸ“Š First chunk: {chunk_size:,} chars (~{estimated_tokens:,} tokens)")
    print(f"ğŸ“ Description: {first_chunk['description']}")
    
    if estimated_tokens > 25000:
        print("âš ï¸ Chunk might be close to 32k output limit")
    else:
        print("âœ… Chunk size looks safe for transformation")
    
    # Create character context
    character_context = "Character information:\n"
    for char in character_list:
        character_context += f"- {char['name']}: {char['gender']}, {char['role']}\n"
    
    # Transform the first chunk
    print(f"\nğŸ¯ TRANSFORMING FIRST CHUNK...")
    start_time = time.time()
    
    try:
        transformed_text, changes = transform_gender_with_context(
            first_chunk['text'], 
            transform_type, 
            character_context,
            model="gpt-4.1-nano"
        )
        
        transform_time = time.time() - start_time
        
        print(f"âœ… Transformation successful in {transform_time:.1f}s!")
        print(f"ğŸ“Š Output length: {len(transformed_text):,} characters")
        print(f"ğŸ”„ Changes made: {len(changes)}")
        
        # Show all changes
        if changes:
            print(f"\nğŸ“‹ ALL CHANGES MADE:")
            for i, change in enumerate(changes, 1):
                print(f"   {i}. {change}")
        
        # Save output if requested
        if save_output:
            output_file = f"transformed_{book_name.lower().replace(' ', '_')}_{transform_type}_chunk1.txt"
            with open(output_file, 'w') as f:
                f.write(transformed_text)
            print(f"\nğŸ’¾ SAVED TRANSFORMED TEXT TO: {output_file}")
        
        # Show sample of transformed text
        print(f"\nğŸ“– SAMPLE TRANSFORMED TEXT (first 500 chars):")
        sample = transformed_text[:500]
        print(f"   {repr(sample)}...")
        
        # Show comparison if save_output is True
        if save_output:
            print(f"\nğŸ” ORIGINAL vs TRANSFORMED:")
            print(f"ğŸ”¸ ORIGINAL (first 200 chars):")
            print(f"   {repr(first_chunk['text'][:200])}...")
            print(f"ğŸ”¹ TRANSFORMED (first 200 chars):")
            print(f"   {repr(transformed_text[:200])}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transformation failed: {e}")
        return False

def main():
    """Main function with command line argument parsing."""
    parser = argparse.ArgumentParser(description='Test AI chunking + gender transformation pipeline')
    
    parser.add_argument('book', nargs='?', default='pride_and_prejudice_full.txt',
                       help='Book filename in test_data/ directory (default: pride_and_prejudice_full.txt)')
    
    parser.add_argument('--transform', '-t', choices=['neutral', 'feminine', 'masculine'], 
                       default='neutral', help='Transformation type (default: neutral)')
    
    parser.add_argument('--save', '-s', action='store_true',
                       help='Save transformed output to file')
    
    parser.add_argument('--all-books', '-a', action='store_true',
                       help='Test all available books')
    
    args = parser.parse_args()
    
    print("ğŸš€ AI CHUNKING + GENDER TRANSFORMATION PIPELINE")
    print("=" * 80)
    
    # Available test books
    test_books = [
        ('test_data/pride_and_prejudice_full.txt', 'Pride and Prejudice'),
        ('test_data/moby_dick_full_text.txt', 'Moby Dick'),
    ]
    
    if args.all_books:
        # Test all books
        all_success = True
        for book_path, book_name in test_books:
            if Path(book_path).exists():
                print(f"\n{'='*80}")
                success = test_pipeline(book_path, book_name, args.transform, args.save)
                if not success:
                    all_success = False
            else:
                print(f"âš ï¸ Skipping {book_name} - file not found: {book_path}")
        
        print(f"\n{'='*80}")
        print(f"ğŸ¯ FINAL RESULT:")
        if all_success:
            print("ğŸ† ALL BOOKS TESTED SUCCESSFULLY!")
            print("ğŸ“š AI chunking + transformation pipeline is ready for production!")
            print("ğŸ’ª Bill's solution doesn't stand a chance!")
        else:
            print("âŒ Some tests failed - pipeline needs refinement")
    else:
        # Test single book
        if args.book.startswith('test_data/'):
            book_path = args.book
        else:
            book_path = f'test_data/{args.book}'
        
        # Get book name from filename
        book_name = Path(book_path).stem.replace('_', ' ').title()
        
        if not Path(book_path).exists():
            print(f"âŒ Book not found: {book_path}")
            print(f"Available books:")
            for book_path, book_name in test_books:
                if Path(book_path).exists():
                    print(f"  - {Path(book_path).name}")
            return 1
        
        success = test_pipeline(book_path, book_name, args.transform, args.save)
        
        print(f"\n{'='*80}")
        print(f"ğŸ¯ PIPELINE RESULT:")
        if success:
            print("ğŸ† COMPLETE SUCCESS - AI PIPELINE WORKS!")
            print("ğŸ“š Ready to transform entire books with AI chunking!")
            print("ğŸ’ª Bill's solution can't compete with this!")
        else:
            print("âŒ Pipeline needs refinement")
        
        return 0 if success else 1

if __name__ == "__main__":
    exit(main())